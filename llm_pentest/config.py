import os
from dotenv import load_dotenv
from pathlib import Path
import logging
from enum import Enum
from typing import List

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class LLMProvider(Enum):
    OPENAI = "openai"
    COHERE = "cohere"
    ANTHROPIC = "anthropic"
    GOOGLE = "google"
    MISTRAL = "mistral"
    AZURE_OPENAI = "azure_openai"
    HUGGINGFACE = "huggingface"
    REPLICATE = "replicate"

# Load environment variables from .env file
env_path = Path(__file__).parent.parent / '.env'
if env_path.exists():
    load_dotenv(env_path)
    logger.info("Loaded environment variables from .env file")
else:
    logger.warning(".env file not found. Using system environment variables.")

# LLM Configuration
LLM_PROVIDER = os.getenv("LLM_PROVIDER", "openai").lower()

# Validate provider
try:
    provider = LLMProvider(LLM_PROVIDER)
    logger.info(f"Using provider: {provider.value}")
except ValueError:
    valid_providers = [p.value for p in LLMProvider]
    raise ValueError(f"Unsupported LLM provider: {LLM_PROVIDER}. Valid providers are: {', '.join(valid_providers)}")

# Provider-specific configurations
PROVIDER_CONFIGS = {
    LLMProvider.OPENAI.value: {
        "provider": LLMProvider.OPENAI.value,
        "api_url": os.getenv("OPENAI_API_URL", "https://api.openai.com/v1/chat/completions"),
        "model": os.getenv("OPENAI_MODEL", "gpt-4"),
        "api_key": os.getenv("OPENAI_API_KEY"),
        "headers": {
            "Authorization": f"Bearer {os.getenv('OPENAI_API_KEY')}",
            "Content-Type": "application/json"
        },
        "available_models": ["gpt-4", "gpt-3.5-turbo", "gpt-4-turbo-preview"]
    },
    LLMProvider.COHERE.value: {
        "provider": LLMProvider.COHERE.value,
        "api_url": os.getenv("COHERE_API_URL", "https://api.cohere.ai/v1/generate"),
        "model": os.getenv("COHERE_MODEL", "command"),
        "api_key": os.getenv("COHERE_API_KEY"),
        "headers": {
            "Authorization": f"Bearer {os.getenv('COHERE_API_KEY')}",
            "Content-Type": "application/json"
        },
        "available_models": ["command", "command-light", "command-nightly"]
    },
    LLMProvider.ANTHROPIC.value: {
        "provider": LLMProvider.ANTHROPIC.value,
        "api_url": os.getenv("ANTHROPIC_API_URL", "https://api.anthropic.com/v1/messages"),
        "model": os.getenv("ANTHROPIC_MODEL", "claude-3-opus"),
        "api_key": os.getenv("ANTHROPIC_API_KEY"),
        "headers": {
            "x-api-key": os.getenv("ANTHROPIC_API_KEY"),
            "anthropic-version": "2023-06-01",
            "Content-Type": "application/json"
        },
        "available_models": ["claude-3-opus", "claude-3-sonnet", "claude-2.1"]
    },
    LLMProvider.GOOGLE.value: {
        "provider": LLMProvider.GOOGLE.value,
        "api_url": os.getenv("GOOGLE_API_URL", "https://generativelanguage.googleapis.com/v1/models"),
        "model": os.getenv("GOOGLE_MODEL", "gemini-pro"),
        "api_key": os.getenv("GOOGLE_API_KEY"),
        "headers": {
            "Content-Type": "application/json"
        },
        "available_models": ["gemini-pro", "gemini-pro-vision"]
    },
    LLMProvider.MISTRAL.value: {
        "provider": LLMProvider.MISTRAL.value,
        "api_url": os.getenv("MISTRAL_API_URL", "https://api.mistral.ai/v1/chat/completions"),
        "model": os.getenv("MISTRAL_MODEL", "mistral-large"),
        "api_key": os.getenv("MISTRAL_API_KEY"),
        "headers": {
            "Authorization": f"Bearer {os.getenv('MISTRAL_API_KEY')}",
            "Content-Type": "application/json"
        },
        "available_models": ["mistral-tiny", "mistral-small", "mistral-medium", "mistral-large"]
    },
    LLMProvider.AZURE_OPENAI.value: {
        "provider": LLMProvider.AZURE_OPENAI.value,
        "api_url": os.getenv("AZURE_OPENAI_ENDPOINT"),
        "model": os.getenv("AZURE_OPENAI_MODEL"),
        "api_key": os.getenv("AZURE_OPENAI_KEY"),
        "headers": {
            "api-key": os.getenv("AZURE_OPENAI_KEY"),
            "Content-Type": "application/json"
        },
        "deployment_name": os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME"),
        "api_version": os.getenv("AZURE_OPENAI_API_VERSION", "2024-02-15-preview")
    },
    LLMProvider.HUGGINGFACE.value: {
        "provider": LLMProvider.HUGGINGFACE.value,
        "api_url": os.getenv("HUGGINGFACE_API_URL", "https://api-inference.huggingface.co/models"),
        "model": os.getenv("HUGGINGFACE_MODEL"),
        "api_key": os.getenv("HUGGINGFACE_API_KEY"),
        "headers": {
            "Authorization": f"Bearer {os.getenv('HUGGINGFACE_API_KEY')}",
            "Content-Type": "application/json"
        }
    },
    LLMProvider.REPLICATE.value: {
        "provider": LLMProvider.REPLICATE.value,
        "api_url": os.getenv("REPLICATE_API_URL", "https://api.replicate.com/v1/predictions"),
        "model": os.getenv("REPLICATE_MODEL"),
        "api_key": os.getenv("REPLICATE_API_KEY"),
        "headers": {
            "Authorization": f"Token {os.getenv('REPLICATE_API_KEY')}",
            "Content-Type": "application/json"
        }
    }
}

def validate_provider_config(provider: str) -> bool:
    """Validate that all required configuration is present for a provider."""
    config = PROVIDER_CONFIGS.get(provider)
    if not config:
        return False
    
    required_fields = ["api_url", "model", "api_key", "headers"]
    return all(config.get(field) for field in required_fields)

def get_available_models(provider: str) -> List[str]:
    """Get list of available models for a provider."""
    config = PROVIDER_CONFIGS.get(provider)
    return config.get("available_models", []) if config else []

# Get current provider configuration
CURRENT_PROVIDER = PROVIDER_CONFIGS.get(provider.value)
if not CURRENT_PROVIDER:
    raise ValueError(f"Configuration missing for provider: {provider.value}")

# Debug environment variables
logger.info(f"LLM Provider: {provider.value}")
logger.info(f"API URL: {CURRENT_PROVIDER['api_url']}")
logger.info(f"Model: {CURRENT_PROVIDER['model']}")
logger.info(f"API Key present: {bool(CURRENT_PROVIDER['api_key'])}")

# Validate required environment variables
if not CURRENT_PROVIDER['api_key']:
    provider_key = f"{provider.value.upper()}_API_KEY"
    logger.error(f"{provider_key} environment variable is not set.")
    logger.info("Current environment variables:")
    for key, value in os.environ.items():
        if key.startswith(("LLM_", "OPENAI_", "COHERE_", "ANTHROPIC_", "GOOGLE_", "MISTRAL_", "AZURE_OPENAI_", "HUGGINGFACE_", "REPLICATE_")):
            logger.info(f"{key}: {value}")
    raise ValueError(f"{provider_key} environment variable is not set. Please set it in your .env file or as a system environment variable.")

# Project paths
PROJECT_ROOT = Path(__file__).parent.parent
DATA_DIR = PROJECT_ROOT / "data"
OUTPUT_DIR = PROJECT_ROOT / "output"

# Create necessary directories
DATA_DIR.mkdir(exist_ok=True)
OUTPUT_DIR.mkdir(exist_ok=True)