import logging
import os
import re
import joblib
import pickle
import numpy as np
from typing import Dict, List, Optional, Union
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import Pipeline
from sklearn.exceptions import NotFittedError
from pathlib import Path

logger = logging.getLogger(__name__)

class AttackTypeClassifier:
    """A classifier for identifying different types of LLM attacks."""
    
    def __init__(self, attack_types: Optional[List[str]] = None):
        """
        Initialize the classifier with a set of attack types.
        
        Args:
            attack_types: List of attack type labels. If None, uses default types.
        """
        self.default_attack_types = [
            "prompt_injection",
            "filter_evasion",
            "social_engineering",
            "data_extraction",
            "model_manipulation"
        ]
        self.attack_types = attack_types if attack_types is not None else self.default_attack_types
        
        # Initialize the ML pipeline
        self.pipeline = Pipeline([
            ('vectorizer', TfidfVectorizer(
                lowercase=True,
                max_features=10000,
                ngram_range=(1, 3)
            )),
            ('classifier', MultinomialNB())
        ])
        
        self.is_trained = False
    
    def _preprocess_text(self, text: str) -> str:
        """
        Preprocess the input text by normalizing it.
        
        Args:
            text: Input text to preprocess.
            
        Returns:
            Preprocessed text.
        """
        # Convert to lowercase
        text = text.lower()
        
        # Remove special characters but keep spaces
        text = re.sub(r'[^a-z0-9\s]', ' ', text)
        
        # Normalize whitespace
        text = ' '.join(text.split())
        
        return text
    
    def train(self, texts: List[str], labels: List[str]) -> None:
        """
        Train the classifier on the provided texts and labels.
        
        Args:
            texts: List of text samples to train on.
            labels: List of corresponding attack type labels.
            
        Raises:
            ValueError: If lengths don't match or labels are invalid.
        """
        if len(texts) != len(labels):
            raise ValueError("Number of texts and labels must match")
            
        # Validate all labels
        invalid_labels = set(labels) - set(self.attack_types)
        if invalid_labels:
            raise ValueError(f"Invalid attack types found: {invalid_labels}")
        
        # Preprocess all texts
        processed_texts = [self._preprocess_text(text) for text in texts]
        
        # Train the pipeline
        self.pipeline.fit(processed_texts, labels)
        self.is_trained = True
    
    def predict(self, text: str) -> str:
        """
        Predict the attack type for the given text.
        
        Args:
            text: Input text to classify.
            
        Returns:
            Predicted attack type label.
            
        Raises:
            RuntimeError: If the model hasn't been trained.
        """
        if not self.is_trained:
            raise RuntimeError("Model must be trained before making predictions")
        
        processed_text = self._preprocess_text(text)
        return self.pipeline.predict([processed_text])[0]
    
    def predict_proba(self, text: str) -> Dict[str, float]:
        """
        Get probability distribution over attack types for the given text.
        
        Args:
            text: Input text to classify.
            
        Returns:
            Dictionary mapping attack types to their probabilities.
            
        Raises:
            RuntimeError: If the model hasn't been trained.
        """
        if not self.is_trained:
            raise RuntimeError("Model must be trained before making predictions")
        
        processed_text = self._preprocess_text(text)
        probas = self.pipeline.predict_proba([processed_text])[0]
        
        return dict(zip(self.attack_types, probas))
    
    def add_attack_type(self, attack_type: str) -> None:
        """
        Add a new attack type to the classifier.
        
        Args:
            attack_type: New attack type label to add.
            
        Raises:
            ValueError: If attack type already exists.
        """
        if attack_type in self.attack_types:
            raise ValueError(f"Attack type '{attack_type}' already exists")
        
        self.attack_types.append(attack_type)
        # Note: Model needs to be retrained with samples of the new attack type
        self.is_trained = False
    
    def remove_attack_type(self, attack_type: str) -> None:
        """
        Remove an attack type from the classifier.
        
        Args:
            attack_type: Attack type label to remove.
            
        Raises:
            ValueError: If attack type doesn't exist.
        """
        if attack_type not in self.attack_types:
            raise ValueError(f"Attack type '{attack_type}' does not exist")
        
        self.attack_types.remove(attack_type)
        # Note: Model needs to be retrained without samples of this attack type
        self.is_trained = False
    
    def save_model(self, path: str) -> None:
        """
        Save the trained model to a file.
        
        Args:
            path: Path where to save the model.
            
        Raises:
            RuntimeError: If the model hasn't been trained.
        """
        if not self.is_trained:
            raise RuntimeError("Cannot save untrained model")
            
        model_data = {
            'pipeline': self.pipeline,
            'attack_types': self.attack_types,
            'is_trained': self.is_trained
        }
        
        with open(path, 'wb') as f:
            pickle.dump(model_data, f)
    
    @classmethod
    def load_model(cls, path: str) -> 'AttackTypeClassifier':
        """
        Load a trained model from a file.
        
        Args:
            path: Path to the saved model file.
            
        Returns:
            Loaded AttackTypeClassifier instance.
        """
        with open(path, 'rb') as f:
            model_data = pickle.load(f)
            
        classifier = cls(attack_types=model_data['attack_types'])
        classifier.pipeline = model_data['pipeline']
        classifier.is_trained = model_data['is_trained']
        
        return classifier
    
    def get_attack_types(self) -> List[str]:
        """Return list of supported attack types."""
        return self.attack_types.copy()
    
    def classify_text(self, text: str) -> Dict[str, float]:
        """
        Classify text into attack types based on pattern matching.
        
        Args:
            text: Text to classify
            
        Returns:
            Dictionary mapping attack types to confidence scores
        """
        scores = {}
        text = text.lower()
        
        for attack_type, patterns in self.patterns.items():
            score = 0.0
            for pattern in patterns:
                matches = len(re.findall(pattern, text, re.IGNORECASE))
                if matches > 0:
                    score += 0.2 * matches  # Each match adds 0.2 to the score
            scores[attack_type] = min(1.0, score)  # Cap score at 1.0
        
        return scores
    
    def get_primary_attack_type(self, scores: Dict[str, float]) -> str:
        """
        Get the primary attack type from classification scores.
        
        Args:
            scores: Dictionary of attack type scores
            
        Returns:
            Name of the primary attack type
        """
        if not scores:
            return "unknown"
        
        return max(scores.items(), key=lambda x: x[1])[0] 